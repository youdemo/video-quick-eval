"""
è§†é¢‘è½¬å†™å·¥å…· - å¢å¼ºç‰ˆï¼ˆæ”¯æŒå¤§æ¨¡å‹æ–‡æœ¬æ•´åˆï¼‰
- å¿«é€Ÿè½¬å†™è§†é¢‘ä¸ºæ–‡æœ¬
- è‡ªåŠ¨è°ƒç”¨å¤§æ¨¡å‹è¿›è¡Œæ–‡æœ¬ä¼˜åŒ–æ•´åˆ
- æ”¯æŒ OpenAIã€Anthropicã€å›½å†…å¤§æ¨¡å‹ç­‰
- æ˜¾ç¤ºæ¯ä¸ªé˜¶æ®µçš„è€—æ—¶
- æ”¯æŒå¤šæç¤ºè¯å¤„ç†
- æ”¯æŒæ‰¹é‡å¤„ç†
"""
import os
import sys
import json
import logging
import time
import argparse
from pathlib import Path
from typing import Optional, List
from datetime import datetime

import yt_dlp
from faster_whisper import WhisperModel
from modelscope import snapshot_download

# ==================== é…ç½® ====================
OUTPUT_DIR = Path("output")
DATA_DIR = Path("data")
MODEL_DIR = Path("models/whisper")
PROMPTS_DIR = Path("prompts")
CONFIG_FILE = Path("config.json")

OUTPUT_DIR.mkdir(exist_ok=True)
DATA_DIR.mkdir(exist_ok=True)
MODEL_DIR.mkdir(exist_ok=True)
PROMPTS_DIR.mkdir(exist_ok=True)
Path("logs").mkdir(exist_ok=True)

# æ—¥å¿—é…ç½®
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
    datefmt="%H:%M:%S",
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler("logs/app.log", encoding="utf-8")
    ]
)
logger = logging.getLogger(__name__)

# Bç«™æœç´¢æ¨¡å—
try:
    from src.bilibili_search import search_bilibili_videos, format_duration, format_play_count
    BILIBILI_SEARCH_AVAILABLE = True
except ImportError:
    BILIBILI_SEARCH_AVAILABLE = False
    logger.warning("Bç«™æœç´¢æ¨¡å—ä¸å¯ç”¨ï¼Œè¯·å®‰è£…: pip install bilibili-api-python")

# ==================== å·¥å…·å‡½æ•° ====================
def format_time(seconds: float) -> str:
    """æ ¼å¼åŒ–æ—¶é—´æ˜¾ç¤º"""
    if seconds < 60:
        return f"{seconds:.1f}ç§’"
    elif seconds < 3600:
        minutes = int(seconds // 60)
        secs = seconds % 60
        return f"{minutes}åˆ†{secs:.0f}ç§’"
    else:
        hours = int(seconds // 3600)
        minutes = int((seconds % 3600) // 60)
        return f"{hours}å°æ—¶{minutes}åˆ†"

def detect_platform(url: str) -> str:
    """æ£€æµ‹è§†é¢‘å¹³å°"""
    url_lower = url.lower()
    if 'bilibili.com' in url_lower or 'b23.tv' in url_lower:
        return 'Bilibili'
    elif 'youtube.com' in url_lower or 'youtu.be' in url_lower:
        return 'YouTube'
    else:
        return 'Unknown'

# ==================== æç¤ºè¯ç®¡ç† ====================
def list_available_prompts() -> List[str]:
    """åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„æç¤ºè¯"""
    prompts = []
    for file in PROMPTS_DIR.glob("*.md"):
        if file.name != "README.md":
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦ä¸ºç©º
            if file.stat().st_size > 0:
                # æ£€æŸ¥æ˜¯å¦åŒ…å«å¿…éœ€çš„å ä½ç¬¦
                try:
                    with open(file, 'r', encoding='utf-8') as f:
                        content = f.read()
                        if content.strip():  # æ–‡ä»¶ä¸ä¸ºç©º
                            prompts.append(file.stem)
                except Exception as e:
                    logger.warning(f"æ— æ³•è¯»å–æç¤ºè¯æ–‡ä»¶ {file}: {e}")
    return sorted(prompts)

def load_prompt(prompt_name: str = "evaluation") -> str:
    """ä» prompts æ–‡ä»¶å¤¹åŠ è½½æç¤ºè¯"""
    prompt_file = PROMPTS_DIR / f"{prompt_name}.md"

    if not prompt_file.exists():
        logger.warning(f"æç¤ºè¯æ–‡ä»¶ä¸å­˜åœ¨: {prompt_file}")
        logger.warning(f"å¯ç”¨çš„æç¤ºè¯: {', '.join(list_available_prompts())}")
        logger.warning("ä½¿ç”¨é»˜è®¤æç¤ºè¯")
        return """è¯·ä¼˜åŒ–ä»¥ä¸‹æ–‡æœ¬ï¼Œå»é™¤å†—ä½™ï¼Œé‡æ„é€»è¾‘ç»“æ„ï¼š

{transcript_text}"""

    with open(prompt_file, 'r', encoding='utf-8') as f:
        content = f.read().strip()

    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦ä¸ºç©º
    if not content:
        logger.error(f"æç¤ºè¯æ–‡ä»¶ä¸ºç©º: {prompt_file}")
        return None

    # æ£€æŸ¥æ˜¯å¦åŒ…å«å¿…éœ€çš„å ä½ç¬¦
    if '{transcript_text}' not in content:
        logger.warning(f"æç¤ºè¯æ–‡ä»¶ç¼ºå°‘ {{transcript_text}} å ä½ç¬¦: {prompt_file}")
        logger.warning("å°†åœ¨æœ«å°¾è‡ªåŠ¨æ·»åŠ å ä½ç¬¦")
        content += "\n\n{transcript_text}"

    return content

# ==================== é…ç½®ç®¡ç† ====================
def load_config() -> dict:
    """åŠ è½½é…ç½®æ–‡ä»¶"""
    if not CONFIG_FILE.exists():
        logger.warning(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {CONFIG_FILE}")
        logger.warning("è¯·å¤åˆ¶ config.example.json ä¸º config.json å¹¶å¡«å…¥ API key")
        return {}

    with open(CONFIG_FILE, 'r', encoding='utf-8') as f:
        return json.load(f)

# ==================== ç¹ç®€è½¬æ¢ ====================
def traditional_to_simplified(text: str) -> str:
    """ç¹ä½“è½¬ç®€ä½“"""
    try:
        from opencc import OpenCC
        cc = OpenCC('t2s')
        return cc.convert(text)
    except ImportError:
        logger.warning("æœªå®‰è£… opencc-python-reimplementedï¼Œè·³è¿‡ç¹ç®€è½¬æ¢")
        return text

# ==================== è§†é¢‘ä¸‹è½½ ====================
def download_audio(video_url: str) -> tuple[str, str]:
    """ä¸‹è½½è§†é¢‘éŸ³é¢‘"""
    start_time = time.time()
    logger.info(f"å¼€å§‹ä¸‹è½½éŸ³é¢‘: {video_url}")

    output_template = str(DATA_DIR / "%(id)s.%(ext)s")

    ydl_opts = {
        'format': 'bestaudio[ext=m4a]/bestaudio/best',
        'outtmpl': output_template,
        'postprocessors': [{
            'key': 'FFmpegExtractAudio',
            'preferredcodec': 'mp3',
            'preferredquality': '64',
        }],
        'noplaylist': True,
        'quiet': True,
        'no_warnings': True,
    }

    with yt_dlp.YoutubeDL(ydl_opts) as ydl:
        info = ydl.extract_info(video_url, download=True)
        video_id = info.get("id")
        title = info.get("title", "æœªçŸ¥æ ‡é¢˜")
        audio_path = str(DATA_DIR / f"{video_id}.mp3")

    elapsed = time.time() - start_time
    logger.info(f"éŸ³é¢‘ä¸‹è½½å®Œæˆ: {title} (è€—æ—¶: {format_time(elapsed)})")
    return audio_path, title

# ==================== éŸ³é¢‘è½¬å†™ ====================
def transcribe_audio(
    audio_path: str,
    model_size: str = "tiny",
    cpu_threads: int = 4
) -> str:
    """è½¬å†™éŸ³é¢‘ä¸ºæ–‡æœ¬"""
    start_time = time.time()
    model_path = MODEL_DIR / f"whisper-{model_size}"

    # ä¸‹è½½æ¨¡å‹ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
    if not model_path.exists():
        logger.info(f"ä¸‹è½½ Whisper {model_size} æ¨¡å‹...")
        model_map = {
            "tiny": "pengzhendong/faster-whisper-tiny",
            "base": "pengzhendong/faster-whisper-base",
            "small": "pengzhendong/faster-whisper-small",
        }
        repo_id = model_map.get(model_size)
        if not repo_id:
            raise ValueError(f"ä¸æ”¯æŒçš„æ¨¡å‹: {model_size}")

        download_start = time.time()
        snapshot_download(repo_id, local_dir=str(model_path))
        download_elapsed = time.time() - download_start
        logger.info(f"æ¨¡å‹ä¸‹è½½å®Œæˆ (è€—æ—¶: {format_time(download_elapsed)})")

    # åŠ è½½æ¨¡å‹
    logger.info(f"åŠ è½½ Whisper æ¨¡å‹ ({model_size})...")
    load_start = time.time()
    model = WhisperModel(
        model_size_or_path=str(model_path),
        device="cpu",
        compute_type="int8",
        cpu_threads=cpu_threads
    )
    load_elapsed = time.time() - load_start
    logger.info(f"æ¨¡å‹åŠ è½½å®Œæˆ (è€—æ—¶: {format_time(load_elapsed)})")

    # è½¬å†™
    logger.info("å¼€å§‹è½¬å†™éŸ³é¢‘...")
    transcribe_start = time.time()
    segments_generator, info = model.transcribe(audio_path, language="zh")

    full_text = ""
    segment_count = 0
    for segment in segments_generator:
        full_text += segment.text.strip() + " "
        segment_count += 1

    full_text = full_text.strip()
    transcribe_elapsed = time.time() - transcribe_start
    logger.info(f"è½¬å†™å®Œæˆ: {segment_count} æ®µ (è€—æ—¶: {format_time(transcribe_elapsed)})")

    # ç¹ç®€è½¬æ¢
    logger.info("ç¹ç®€è½¬æ¢...")
    convert_start = time.time()
    full_text = traditional_to_simplified(full_text)
    convert_elapsed = time.time() - convert_start
    logger.info(f"ç¹ç®€è½¬æ¢å®Œæˆ (è€—æ—¶: {format_time(convert_elapsed)})")

    total_elapsed = time.time() - start_time
    logger.info(f"è½¬å†™æ€»è€—æ—¶: {format_time(total_elapsed)}, å…± {len(full_text)} å­—ç¬¦")
    return full_text

# ==================== å¤§æ¨¡å‹æ–‡æœ¬ä¼˜åŒ– ====================
def optimize_text_with_llm(text: str, config: dict, prompt_name: str = "evaluation") -> Optional[str]:
    """ä½¿ç”¨å¤§æ¨¡å‹ä¼˜åŒ–æ–‡æœ¬"""
    if not config or 'llm' not in config:
        logger.warning("æœªé…ç½®å¤§æ¨¡å‹ï¼Œè·³è¿‡æ–‡æœ¬ä¼˜åŒ–")
        return None

    llm_config = config['llm']
    provider = llm_config.get('provider', 'openai')

    logger.info(f"ä½¿ç”¨ {provider} å’Œæç¤ºè¯ '{prompt_name}' è¿›è¡Œæ–‡æœ¬ä¼˜åŒ–...")

    try:
        if provider == 'openai':
            return _optimize_with_openai(text, llm_config, prompt_name)
        elif provider == 'anthropic':
            return _optimize_with_anthropic(text, llm_config, prompt_name)
        else:
            logger.error(f"ä¸æ”¯æŒçš„æä¾›å•†: {provider}")
            return None
    except Exception as e:
        logger.error(f"æ–‡æœ¬ä¼˜åŒ–å¤±è´¥: {e}")
        return None

def _optimize_with_openai(text: str, config: dict, prompt_name: str) -> str:
    """ä½¿ç”¨ OpenAI API ä¼˜åŒ–æ–‡æœ¬"""
    try:
        from openai import OpenAI
    except ImportError:
        logger.error("æœªå®‰è£… openai åº“ï¼Œè¯·è¿è¡Œ: pip install openai")
        return None

    start_time = time.time()

    client = OpenAI(
        api_key=config.get('api_key'),
        base_url=config.get('base_url', 'https://api.openai.com/v1')
    )

    # åŠ è½½æç¤ºè¯æ¨¡æ¿
    prompt_template = load_prompt(prompt_name)
    prompt = prompt_template.format(transcript_text=text)

    try:
        response = client.chat.completions.create(
            model=config.get('model', 'gpt-4o-mini'),
            messages=[
                {"role": "user", "content": prompt}
            ],
            temperature=config.get('temperature', 0.3),
            max_tokens=config.get('max_tokens', 4000)
        )

        # å¤„ç†ä¸åŒçš„å“åº”æ ¼å¼
        if hasattr(response, 'choices'):
            optimized_text = response.choices[0].message.content
        elif isinstance(response, dict):
            optimized_text = response.get('choices', [{}])[0].get('message', {}).get('content', '')
        elif isinstance(response, str):
            if response.strip().startswith('<!doctype') or response.strip().startswith('<html'):
                logger.error("API è¿”å›äº† HTML é¡µé¢è€Œä¸æ˜¯ JSON å“åº”")
                return None
            optimized_text = response
        else:
            logger.error(f"æœªçŸ¥çš„å“åº”æ ¼å¼: {type(response)}")
            return None

        if not optimized_text:
            logger.error("API è¿”å›ç©ºå†…å®¹")
            return None

        if optimized_text.strip().startswith('<!doctype') or optimized_text.strip().startswith('<html'):
            logger.error("API è¿”å›äº† HTML é¡µé¢è€Œä¸æ˜¯æ–‡æœ¬å†…å®¹")
            return None

        elapsed = time.time() - start_time
        logger.info(f"æ–‡æœ¬ä¼˜åŒ–å®Œæˆ (è€—æ—¶: {format_time(elapsed)})")
        return optimized_text

    except Exception as e:
        logger.error(f"API è°ƒç”¨å¤±è´¥: {e}")
        if hasattr(e, 'response'):
            logger.error(f"HTTP çŠ¶æ€ç : {getattr(e.response, 'status_code', 'unknown')}")
        return None

def _optimize_with_anthropic(text: str, config: dict, prompt_name: str) -> str:
    """ä½¿ç”¨ Anthropic API ä¼˜åŒ–æ–‡æœ¬"""
    try:
        from anthropic import Anthropic
    except ImportError:
        logger.error("æœªå®‰è£… anthropic åº“ï¼Œè¯·è¿è¡Œ: pip install anthropic")
        return None

    start_time = time.time()
    client = Anthropic(api_key=config.get('api_key'))

    prompt_template = load_prompt(prompt_name)
    prompt = prompt_template.format(transcript_text=text)

    response = client.messages.create(
        model=config.get('model', 'claude-3-5-sonnet-20241022'),
        max_tokens=config.get('max_tokens', 4000),
        temperature=config.get('temperature', 0.3),
        messages=[
            {"role": "user", "content": prompt}
        ]
    )

    optimized_text = response.content[0].text
    elapsed = time.time() - start_time
    logger.info(f"æ–‡æœ¬ä¼˜åŒ–å®Œæˆ (è€—æ—¶: {format_time(elapsed)})")
    return optimized_text

# ==================== ä¸»å‡½æ•° ====================
def process_video(
    video_url: str,
    model_size: str = "tiny",
    cpu_threads: int = 4,
    enable_llm_optimization: bool = True,
    prompt_names: List[str] = None
) -> dict:
    """å¤„ç†è§†é¢‘ï¼šä¸‹è½½ + è½¬å†™ + ä¼˜åŒ–"""
    total_start = time.time()

    # æ£€æµ‹å¹³å°
    platform = detect_platform(video_url)

    print("\n" + "=" * 60)
    print("è§†é¢‘è½¬å†™å·¥å…·ï¼ˆå¢å¼ºç‰ˆ - æ”¯æŒå¤§æ¨¡å‹ä¼˜åŒ–ï¼‰")
    print(f"å¹³å°: {platform}")
    print("=" * 60 + "\n")

    # åŠ è½½é…ç½®
    config = load_config()

    # å¦‚æœæ²¡æœ‰æŒ‡å®šæç¤ºè¯ï¼Œä½¿ç”¨ç©ºåˆ—è¡¨ï¼ˆç”±è°ƒç”¨æ–¹å†³å®šé»˜è®¤è¡Œä¸ºï¼‰
    if prompt_names is None:
        prompt_names = []

    # 1. ä¸‹è½½éŸ³é¢‘
    print(f"ğŸ“¥ æ­¥éª¤ 1: ä¸‹è½½éŸ³é¢‘ ({platform})...")
    try:
        audio_path, title = download_audio(video_url)
    except Exception as e:
        logger.error(f"ä¸‹è½½å¤±è´¥: {e}")
        return {"success": False, "error": str(e), "video_url": video_url, "platform": platform}

    # 2. è½¬å†™éŸ³é¢‘
    print("\nğŸ¤ æ­¥éª¤ 2: è½¬å†™éŸ³é¢‘...")
    try:
        transcript_text = transcribe_audio(audio_path, model_size, cpu_threads)
    except Exception as e:
        logger.error(f"è½¬å†™å¤±è´¥: {e}")
        return {"success": False, "error": str(e), "video_url": video_url, "title": title}

    # 3. å¤§æ¨¡å‹ä¼˜åŒ–ï¼ˆå¯é€‰ï¼Œæ”¯æŒå¤šæç¤ºè¯é“¾å¼å¤„ç†ï¼‰
    optimized_texts = {}
    formatted_text = transcript_text  # é»˜è®¤ä½¿ç”¨åŸå§‹è½¬å†™

    if enable_llm_optimization and prompt_names:
        print(f"\nğŸ¤– æ­¥éª¤ 3: å¤§æ¨¡å‹ä¼˜åŒ– (ä½¿ç”¨ {len(prompt_names)} ä¸ªæç¤ºè¯)...")

        # æ£€æŸ¥æ˜¯å¦æœ‰ format æç¤ºè¯ï¼Œå¦‚æœæœ‰åˆ™ä¼˜å…ˆå¤„ç†
        if "format" in prompt_names:
            print(f"   - ä½¿ç”¨æç¤ºè¯: format (æ ¼å¼åŒ–è½¬å½•ç¨¿)")

            # å…ˆæ£€æŸ¥æç¤ºè¯æ˜¯å¦æœ‰æ•ˆ
            prompt_template = load_prompt("format")
            if prompt_template:
                formatted_text = optimize_text_with_llm(transcript_text, config, "format")
                if formatted_text:
                    optimized_texts["format"] = formatted_text
                    print(f"     âœ“ æ ¼å¼åŒ–å®Œæˆï¼Œåç»­æç¤ºè¯å°†ä½¿ç”¨æ ¼å¼åŒ–åçš„æ–‡æœ¬")
                else:
                    logger.warning("æ ¼å¼åŒ–å¤±è´¥ï¼Œåç»­æç¤ºè¯å°†ä½¿ç”¨åŸå§‹è½¬å†™")
                    formatted_text = transcript_text
            else:
                logger.warning("format æç¤ºè¯æ— æ•ˆï¼Œè·³è¿‡")

            # ä»åˆ—è¡¨ä¸­ç§»é™¤ formatï¼Œé¿å…é‡å¤å¤„ç†
            prompt_names = [p for p in prompt_names if p != "format"]

        # å¤„ç†å…¶ä»–æç¤ºè¯ï¼ˆä½¿ç”¨æ ¼å¼åŒ–åçš„æ–‡æœ¬ï¼‰
        for prompt_name in prompt_names:
            print(f"   - ä½¿ç”¨æç¤ºè¯: {prompt_name}")

            # å…ˆæ£€æŸ¥æç¤ºè¯æ˜¯å¦æœ‰æ•ˆ
            prompt_template = load_prompt(prompt_name)
            if not prompt_template:
                logger.warning(f"è·³è¿‡æ— æ•ˆçš„æç¤ºè¯: {prompt_name}")
                continue

            # ä½¿ç”¨æ ¼å¼åŒ–åçš„æ–‡æœ¬
            optimized_text = optimize_text_with_llm(formatted_text, config, prompt_name)
            if optimized_text:
                optimized_texts[prompt_name] = optimized_text

    # 4. ä¿å­˜ç»“æœ
    print("\nğŸ’¾ æ­¥éª¤ 4: ä¿å­˜ç»“æœ...")
    save_start = time.time()

    # ç”Ÿæˆæ—¶é—´æˆ³ï¼ˆæ ¼å¼ï¼šYYMMDDï¼‰
    timestamp = datetime.now().strftime("%y%m%d")

    safe_title = "".join(c for c in title if c.isalnum() or c in (' ', '-', '_'))[:50]

    # ä¿å­˜åŸå§‹è½¬å†™
    raw_file = OUTPUT_DIR / f"{timestamp}_{safe_title}_raw.md"
    with open(raw_file, "w", encoding="utf-8") as f:
        f.write(f"# {title}\n\n")
        f.write(f"**è§†é¢‘é“¾æ¥**: {video_url}\n\n")
        f.write("---\n\n")
        f.write("## åŸå§‹è½¬å†™\n\n")
        f.write(transcript_text)

    # ä¿å­˜ä¼˜åŒ–ç‰ˆæœ¬ï¼ˆå¤šä¸ªï¼‰
    optimized_files = {}
    for prompt_name, optimized_text in optimized_texts.items():
        optimized_file = OUTPUT_DIR / f"{timestamp}_{safe_title}_{prompt_name}.md"
        with open(optimized_file, "w", encoding="utf-8") as f:
            f.write(f"# {title}\n\n")
            f.write(f"**è§†é¢‘é“¾æ¥**: {video_url}\n\n")
            f.write(f"**æç¤ºè¯**: {prompt_name}\n\n")
            f.write("---\n\n")
            f.write(optimized_text)
        optimized_files[prompt_name] = str(optimized_file)

    save_elapsed = time.time() - save_start
    logger.info(f"ç»“æœä¿å­˜å®Œæˆ (è€—æ—¶: {format_time(save_elapsed)})")

    # æ€»è€—æ—¶
    total_elapsed = time.time() - total_start

    print("\n" + "=" * 60)
    print("âœ… å¤„ç†å®Œæˆï¼")
    print(f"â±ï¸  æ€»è€—æ—¶: {format_time(total_elapsed)}")
    print(f"ğŸ“„ åŸå§‹è½¬å†™: {raw_file}")
    for prompt_name, file_path in optimized_files.items():
        print(f"âœ¨ ä¼˜åŒ–ç‰ˆæœ¬ ({prompt_name}): {file_path}")
    print("=" * 60)

    # æ‰“å°é¢„è§ˆ
    print("\nåŸå§‹è½¬å†™é¢„è§ˆ:")
    print("-" * 60)
    print(transcript_text[:200] + ("..." if len(transcript_text) > 200 else ""))
    print("-" * 60)

    return {
        "success": True,
        "title": title,
        "video_url": video_url,
        "platform": platform,
        "raw_file": str(raw_file),
        "optimized_files": optimized_files,
        "transcript_text": transcript_text,
        "optimized_texts": optimized_texts,
        "total_time": total_elapsed
    }

# ==================== æ‰¹é‡å¤„ç† ====================
def process_batch(
    video_urls: List[str],
    model_size: str = "tiny",
    cpu_threads: int = 4,
    enable_llm_optimization: bool = True,
    prompt_names: List[str] = None
) -> List[dict]:
    """æ‰¹é‡å¤„ç†å¤šä¸ªè§†é¢‘"""
    print("\n" + "=" * 60)
    print(f"æ‰¹é‡å¤„ç†æ¨¡å¼ - å…± {len(video_urls)} ä¸ªè§†é¢‘")
    print("=" * 60)

    results = []
    for i, url in enumerate(video_urls, 1):
        print(f"\n{'='*60}")
        print(f"å¤„ç†ç¬¬ {i}/{len(video_urls)} ä¸ªè§†é¢‘")
        print(f"{'='*60}")

        try:
            result = process_video(
                video_url=url,
                model_size=model_size,
                cpu_threads=cpu_threads,
                enable_llm_optimization=enable_llm_optimization,
                prompt_names=prompt_names
            )
            results.append(result)
        except Exception as e:
            logger.error(f"å¤„ç†è§†é¢‘å¤±è´¥: {url}, é”™è¯¯: {e}")
            results.append({
                "success": False,
                "video_url": url,
                "error": str(e)
            })

    # ç”Ÿæˆæ‰¹é‡å¤„ç†æŠ¥å‘Š
    print("\n" + "=" * 60)
    print("æ‰¹é‡å¤„ç†å®Œæˆï¼")
    print("=" * 60)

    success_count = sum(1 for r in results if r.get("success", False))
    fail_count = len(results) - success_count

    print(f"\nâœ… æˆåŠŸ: {success_count} ä¸ª")
    print(f"âŒ å¤±è´¥: {fail_count} ä¸ª")

    if fail_count > 0:
        print("\nå¤±è´¥çš„è§†é¢‘:")
        for r in results:
            if not r.get("success", False):
                print(f"  - {r.get('video_url', 'unknown')}: {r.get('error', 'unknown error')}")

    # ä¿å­˜æ‰¹é‡å¤„ç†æŠ¥å‘Š
    report_file = OUTPUT_DIR / f"batch_report_{int(time.time())}.json"
    with open(report_file, "w", encoding="utf-8") as f:
        json.dump(results, f, ensure_ascii=False, indent=2)

    print(f"\nğŸ“Š è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜: {report_file}")

    return results

# ==================== å‘½ä»¤è¡Œå…¥å£ ====================
def main():
    """å‘½ä»¤è¡Œå…¥å£"""
    parser = argparse.ArgumentParser(
        description="è§†é¢‘è½¬å†™å·¥å…· - æ”¯æŒå¤šæç¤ºè¯å’Œæ‰¹é‡å¤„ç†",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  # äº¤äº’å¼è¿è¡Œ
  python transcribe.py

  # å•ä¸ªè§†é¢‘ï¼Œä½¿ç”¨é»˜è®¤æç¤ºè¯
  python transcribe.py --url "https://www.bilibili.com/video/BV1xxx"

  # å•ä¸ªè§†é¢‘ï¼Œä½¿ç”¨å¤šä¸ªæç¤ºè¯
  python transcribe.py --url "https://..." --prompts evaluation,summary

  # æ‰¹é‡å¤„ç†
  python transcribe.py --batch urls.txt

  # Bç«™æœç´¢å¹¶è½¬å½•ï¼ˆé»˜è®¤å‰5ä¸ªï¼‰
  python transcribe.py --search "Pythonæ•™ç¨‹"

  # Bç«™æœç´¢å¹¶è½¬å½•å‰10ä¸ª
  python transcribe.py --search "Pythonæ•™ç¨‹" --search-count 10

  # åˆ—å‡ºå¯ç”¨çš„æç¤ºè¯
  python transcribe.py --list-prompts
        """
    )

    parser.add_argument('--url', type=str, help='è§†é¢‘é“¾æ¥')
    parser.add_argument('--batch', type=str, help='æ‰¹é‡å¤„ç†æ–‡ä»¶ï¼ˆæ¯è¡Œä¸€ä¸ª URLï¼‰')
    parser.add_argument('--search', type=str, help='Bç«™æœç´¢å…³é”®è¯')
    parser.add_argument('--search-count', type=int, default=5, help='æœç´¢ç»“æœæ•°é‡ï¼ˆé»˜è®¤5ï¼‰')
    parser.add_argument('--search-order', type=str, default='totalrank',
                        choices=['totalrank', 'pubdate', 'click', 'dm'],
                        help='æœç´¢æ’åºæ–¹å¼ï¼štotalrank=ç»¼åˆæ’åº, pubdate=æœ€æ–°å‘å¸ƒ, click=æœ€å¤šæ’­æ”¾, dm=æœ€å¤šå¼¹å¹•')
    parser.add_argument('--prompts', type=str, help='æç¤ºè¯åç§°ï¼Œå¤šä¸ªç”¨é€—å·åˆ†éš”ï¼ˆå¦‚: evaluation,summaryï¼‰')
    parser.add_argument('--no-llm', action='store_true', help='ç¦ç”¨å¤§æ¨¡å‹ä¼˜åŒ–')
    parser.add_argument('--model-size', type=str, default='tiny', choices=['tiny', 'base', 'small'], help='Whisper æ¨¡å‹å¤§å°')
    parser.add_argument('--cpu-threads', type=int, default=4, help='CPU çº¿ç¨‹æ•°')
    parser.add_argument('--list-prompts', action='store_true', help='åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„æç¤ºè¯')

    args = parser.parse_args()

    # åˆ—å‡ºå¯ç”¨æç¤ºè¯
    if args.list_prompts:
        prompts = list_available_prompts()
        print("\nå¯ç”¨çš„æç¤ºè¯:")
        for prompt in prompts:
            print(f"  - {prompt}")
        return

    # è§£ææç¤ºè¯
    prompt_names = None
    if args.prompts:
        prompt_names = [p.strip() for p in args.prompts.split(',')]
        # éªŒè¯æç¤ºè¯æ˜¯å¦å­˜åœ¨
        available = list_available_prompts()
        for p in prompt_names:
            if p not in available:
                print(f"é”™è¯¯: æç¤ºè¯ '{p}' ä¸å­˜åœ¨")
                print(f"å¯ç”¨çš„æç¤ºè¯: {', '.join(available)}")
                return

    # Bç«™æœç´¢æ¨¡å¼
    if args.search:
        if not BILIBILI_SEARCH_AVAILABLE:
            print("é”™è¯¯: Bç«™æœç´¢åŠŸèƒ½ä¸å¯ç”¨")
            print("è¯·å®‰è£…ä¾èµ–: pip install bilibili-api-python")
            return

        print(f"\nğŸ” æœç´¢Bç«™è§†é¢‘: {args.search}")
        print(f"   æ•°é‡: {args.search_count}")
        print(f"   æ’åº: {args.search_order}")

        # æœç´¢è§†é¢‘
        videos = search_bilibili_videos(
            keyword=args.search,
            count=args.search_count,
            order=args.search_order
        )

        if not videos:
            print("é”™è¯¯: æœç´¢æ— ç»“æœæˆ–æœç´¢å¤±è´¥")
            return

        # æ˜¾ç¤ºæœç´¢ç»“æœ
        print(f"\nğŸ“Š æ‰¾åˆ° {len(videos)} ä¸ªè§†é¢‘:")
        for i, video in enumerate(videos, 1):
            print(f"  {i}. {video['title']}")
            print(f"     æ—¶é•¿: {format_duration(video['duration'])}, "
                  f"æ’­æ”¾: {format_play_count(video['play'])}, "
                  f"UPä¸»: {video['author']}")

        # æå–URLåˆ—è¡¨
        urls = [video['url'] for video in videos]

        # å¦‚æœæ²¡æœ‰æŒ‡å®šæç¤ºè¯ï¼Œä½¿ç”¨æ‰€æœ‰å¯ç”¨çš„æç¤ºè¯
        if prompt_names is None:
            prompt_names = list_available_prompts()
            if prompt_names:
                print(f"\næœªæŒ‡å®šæç¤ºè¯ï¼Œå°†ä½¿ç”¨æ‰€æœ‰å¯ç”¨çš„æç¤ºè¯: {', '.join(prompt_names)}")
            else:
                print("\nè­¦å‘Š: æœªæ‰¾åˆ°å¯ç”¨çš„æç¤ºè¯ï¼Œå°†åªè¿›è¡ŒåŸå§‹è½¬å†™")

        # è°ƒç”¨æ‰¹é‡å¤„ç†
        print(f"\nğŸ¬ å¼€å§‹æ‰¹é‡è½¬å½•...")
        process_batch(
            video_urls=urls,
            model_size=args.model_size,
            cpu_threads=args.cpu_threads,
            enable_llm_optimization=not args.no_llm,
            prompt_names=prompt_names
        )
        return

    # æ‰¹é‡å¤„ç†æ¨¡å¼
    if args.batch:
        batch_file = Path(args.batch)
        if not batch_file.exists():
            print(f"é”™è¯¯: æ‰¹é‡å¤„ç†æ–‡ä»¶ä¸å­˜åœ¨: {batch_file}")
            return

        with open(batch_file, 'r', encoding='utf-8') as f:
            urls = [line.strip() for line in f if line.strip() and not line.startswith('#')]

        if not urls:
            print("é”™è¯¯: æ‰¹é‡å¤„ç†æ–‡ä»¶ä¸ºç©º")
            return

        # å¦‚æœæ²¡æœ‰æŒ‡å®šæç¤ºè¯ï¼Œä½¿ç”¨æ‰€æœ‰å¯ç”¨çš„æç¤ºè¯
        if prompt_names is None:
            prompt_names = list_available_prompts()
            if prompt_names:
                print(f"æœªæŒ‡å®šæç¤ºè¯ï¼Œå°†ä½¿ç”¨æ‰€æœ‰å¯ç”¨çš„æç¤ºè¯: {', '.join(prompt_names)}")
            else:
                print("è­¦å‘Š: æœªæ‰¾åˆ°å¯ç”¨çš„æç¤ºè¯ï¼Œå°†åªè¿›è¡ŒåŸå§‹è½¬å†™")

        process_batch(
            video_urls=urls,
            model_size=args.model_size,
            cpu_threads=args.cpu_threads,
            enable_llm_optimization=not args.no_llm,
            prompt_names=prompt_names
        )
        return

    # å•ä¸ªè§†é¢‘å¤„ç†
    video_url = args.url
    if not video_url:
        # äº¤äº’å¼æ¨¡å¼
        print("\nè¯·è¾“å…¥è§†é¢‘é“¾æ¥:")
        video_url = input("> ").strip()

        if not video_url:
            print("é”™è¯¯: è¯·è¾“å…¥æœ‰æ•ˆçš„è§†é¢‘é“¾æ¥")
            return

        # è¯¢é—®æ˜¯å¦å¯ç”¨å¤§æ¨¡å‹
        if not args.no_llm:
            print("\næ˜¯å¦å¯ç”¨å¤§æ¨¡å‹æ–‡æœ¬ä¼˜åŒ–ï¼Ÿ(y/nï¼Œé»˜è®¤ y):")
            enable_opt = input("> ").strip().lower()
            enable_llm = enable_opt != 'n'

            if enable_llm and not prompt_names:
                # æ˜¾ç¤ºå¯ç”¨æç¤ºè¯
                available = list_available_prompts()
                print(f"\nå¯ç”¨çš„æç¤ºè¯: {', '.join(available)}")
                print("è¯·é€‰æ‹©æç¤ºè¯ï¼ˆå¤šä¸ªç”¨é€—å·åˆ†éš”ï¼Œç›´æ¥å›è½¦åˆ™é€‰æ‹©å…¨éƒ¨ï¼‰:")
                prompts_input = input("> ").strip()

                if prompts_input:
                    # å¦‚æœç”¨æˆ·è¾“å…¥äº†å†…å®¹ï¼Œå°±æŒ‰ç”¨æˆ·è¾“å…¥çš„æ¥
                    prompt_names = [p.strip() for p in prompts_input.split(',')]
                else:
                    # å¦‚æœç”¨æˆ·æ²¡è¾“å…¥å†…å®¹ï¼ˆç›´æ¥å›è½¦ï¼‰ï¼Œå°±ä½¿ç”¨å…¨éƒ¨å¯ç”¨çš„æç¤ºè¯
                    prompt_names = available

        else:
            enable_llm = False
    else:
        # å‘½ä»¤è¡Œæ¨¡å¼
        enable_llm = not args.no_llm

        # å¦‚æœæ²¡æœ‰æŒ‡å®šæç¤ºè¯ï¼Œä½¿ç”¨æ‰€æœ‰å¯ç”¨çš„æç¤ºè¯
        if enable_llm and prompt_names is None:
            prompt_names = list_available_prompts()
            if prompt_names:
                print(f"æœªæŒ‡å®šæç¤ºè¯ï¼Œå°†ä½¿ç”¨æ‰€æœ‰å¯ç”¨çš„æç¤ºè¯: {', '.join(prompt_names)}")
            else:
                print("è­¦å‘Š: æœªæ‰¾åˆ°å¯ç”¨çš„æç¤ºè¯ï¼Œå°†åªè¿›è¡ŒåŸå§‹è½¬å†™")

    try:
        process_video(
            video_url=video_url,
            model_size=args.model_size,
            cpu_threads=args.cpu_threads,
            enable_llm_optimization=enable_llm,
            prompt_names=prompt_names
        )
    except Exception as e:
        logger.error(f"å¤„ç†å¤±è´¥: {e}")
        print(f"\né”™è¯¯: {e}")

if __name__ == "__main__":
    main()
